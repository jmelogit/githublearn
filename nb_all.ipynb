{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions to Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {} # your dict. What does the f in 'd[f'{file}']' does?\n",
    "for file in dir_files:\n",
    "    d[f'{file}']= pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ? df.reindex(level=[0,1,2], [range_order, colour_order, fin_order] ) - THIS DOESN'T WORK. Using one line for each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ? ap5a_opex = ap5a.loc[~ap5a['Account'].str[:4].isin ([capex,prod_purchases,winemaking,hospo])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ? Unsure how to call the sheets as dataframes\n",
    "\n",
    "bs = pd.ExcelFile('Suppliers and Bills Coding.xlsx')\n",
    "\n",
    "for name in bs.sheet_names:\n",
    "    df = pd.read_excel(bs, name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as op\n",
    "import numpy as np\n",
    "import glob\n",
    "import os #e.g. get paths, folders list of files and change active folders\n",
    "import sys # e.g. get python executable folder\n",
    "import platform # e.g. information on python version used\n",
    "import math\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display more then one output for each cell run (if there is more than one)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Display more columns\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "# Display format\n",
    "pd.set_option('display.float.format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cash Flow Reports (AR, AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original reports exported from NetSuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'P:\\Finance\\0-Routine Activities\\1-Cashflow management\\Reports\\Process files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = pd.read_excel('Cash Flow DB - AP - 2020-10-12.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = pd.read_excel('Invoices for cash flow.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filling empty line item cells for Due Date and Name (supplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap1=ap.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap1 = ap1.rename(columns = {'Amount.1':'Installment Amount', 'Status.1':\"Installment Status\"})\n",
    "ap1['Department'] = ap1['Department'].fillna(method='bfill')\n",
    "ap1['Name'] = ap1['Name'].fillna(method='ffill')\n",
    "ap1['Due Date/Receive By'] = ap1['Due Date/Receive By'].fillna(method='ffill')\n",
    "ap1['Installment Number'] = ap1['Installment Number'].fillna(0)\n",
    "ap1['Due Date'] = ap1['Due Date'].fillna(ap1['Due Date/Receive By'])\n",
    "payment_term = (ap1['Due Date/Receive By'] - ap1['Date']).dt.days\n",
    "entered_to_due = (ap1['Due Date/Receive By'] - ap1['Date Created']).dt.days\n",
    "ap1.insert(5,'Payment Term', payment_term)\n",
    "ap1.insert(6,'Entered to Due', entered_to_due)\n",
    "ap1.insert(21,'Payment Amount', np.where(ap1['Installment Number'] != 0, ap1['Installment Amount'], ap1['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ap1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Open BILLS with due date after a given date (e.g. 2 months ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN LINE\n",
    "ap1a = ap1[(ap1['Status']=='Open') & (ap1['Due Date/Receive By']>='2020-05-01') & (ap1['*']=='*') & (ap1['Installment Status'] != 'Paid')]\n",
    "\n",
    "# lINE ITEMS\n",
    "ap1b = ap1[(ap1['Status']=='Open') & (ap1['Due Date/Receive By']>='2020-05-01') & (ap1['*']!='*')]\n",
    "\n",
    "# td Create workflow to alert me anytime a bill over $20k is entered in the NetSuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Open INVOICES with due date after a given date (e.g. 2 months ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MAIN LINE\n",
    "ar1a = ar[(ar['Status']=='Open') & (ar['Due Date/Receive By']>='2020-05-01') & (ar['*']=='*')]\n",
    "\n",
    "# LINE ITEMS\n",
    "ar1b = ar[(ar['Status']=='Open') & (ar['Due Date/Receive By']>='2020-05-01') & (ar['*']!='*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Profile\n",
    "'''\n",
    "Number of bills, suppliers and amount by department and total\n",
    "Histogram of bills by amount bins\n",
    "\n",
    "'''\n",
    "# Exception Reports\n",
    " '''\n",
    " BILLS\n",
    " No department\n",
    " No GL account\n",
    " GL account different than default\n",
    " Department different than default\n",
    " Created less than 10 days before due\n",
    " Created more than 5 days after issued\n",
    " Payment terms less than 15 days\n",
    " \n",
    " SUPPLIERS\n",
    " No default department\n",
    " No default GL account\n",
    " Suppliers with more than one department\n",
    " Suppliers with more than one GL account\n",
    " \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap1b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t1 = pd.DataFrame(ap1b.groupby(['Name'])['Account'].nunique())\n",
    "t1 = t1.sort_values('Account', ascending=False)\n",
    "t1 = t1.loc[t1.Account>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Bills exception reports: no department, matching with default coding (GL account and Department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'P:\\Finance\\2-Projects\\Finance Processes Improvement\\Financial Infrastructure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs = pd.read_excel('Suppliers and Bills Coding.xlsx', sheet_name = ['MD_Export', 'MD_RT', 'Bills_Export'])\n",
    "\n",
    "ns_md = bs['MD_Export']\n",
    "ws_rt = bs['MD_RT']\n",
    "bills = bs['Bills_Export']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bills['Department'] = bills['Department'].fillna(method='bfill', limit=1)\n",
    "bills['Name'] = bills['Name'].fillna(method='ffill')\n",
    "bills['Due Date/Receive By'] = bills['Due Date/Receive By'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### No department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_dept = bills.loc[(bills.Department.isna()) & (bills['*'] == '*') & (bills['Date Created'].dt.year == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Multi department and multi GL account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bills_lines_to_match = bills.loc[(bills['Department'].notna()) \\\n",
    "                                 & (~bills['Name'].str.contains('Inland')) \\\n",
    "                                 & (bills['*'] != '*') \\\n",
    "                                 & (bills['Date Created'] >= '2020-07-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bills_lines_to_match = bills_lines_to_match.drop_duplicates(['Name','Document Number','Account', 'Department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bills_lines_to_match.to_excel('Bills lines to match text.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Multi department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_dept1 = bills_lines_to_match.groupby(['Name'])[['Department']].nunique()\n",
    "multi_dept1 = multi_dept1.loc[multi_dept1['Department'] >1].sort_values('Department', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_dept_aux = bills_lines_to_match.set_index(bills_lines_to_match['Name']).drop(columns = 'Name')\n",
    "multi_dept_aux = multi_dept_aux.loc[(multi_dept1.index),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_dept2 = multi_dept_aux.groupby(['Name','Department'])[['Date Created']].agg(['max','count'])\n",
    "multi_dept2[('Date Created','max')] = multi_dept2[('Date Created','max')].dt.strftime('%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Multi GL account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gl1 = bills_lines_to_match.groupby(['Name'])[['Account']].nunique()\n",
    "multi_gl1 = multi_gl1.loc[multi_gl1['Account'] >1].sort_values('Account', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gl_aux = bills_lines_to_match.set_index(bills_lines_to_match['Name']).drop(columns = 'Name')\n",
    "multi_gl_aux = multi_gl_aux.loc[(multi_gl1.index),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gl2 = multi_gl_aux.groupby(['Name','Account']).agg({'Date Created':['max','count'], 'Document Number' : 'max'})\n",
    "multi_gl2[('Date Created','max')] = multi_gl2[('Date Created','max')].dt.strftime('%d-%b-%y')\n",
    "multi_gl2.columns = [('Last Document Created On'), ('Document Count'), ('Sample Document')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open bills - Supplier View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap2a = ap1a.pivot_table(index=['Department'], columns=['Due Date/Receive By'], values='Amount', aggfunc='sum')\n",
    "ap2a = ap2a.resample('M', axis=1).sum()\n",
    "ap2a.columns = ap2a.columns.strftime('%b-%y')\n",
    "ap2a['Total'] = ap2a.sum(axis=1)\n",
    "ap2a.loc['TOTAL'] = ap2a.sum(axis=0)\n",
    "ap2a = ap2a.sort_values(by=['Department','Total'], ascending=[True,False])\n",
    "ap2a_name = 'ap_op_grp_by_dept'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by department/supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap2b = ap1a\n",
    "ap2b = ap2b.pivot_table(index=['Department','Name'], columns='Due Date/Receive By', values='Amount', aggfunc='sum')\n",
    "ap2b = ap2b.resample('M', axis=1).sum()\n",
    "ap2b.columns = ap2b.columns.strftime('%b-%y')\n",
    "ap2b['Total'] = ap2b.sum(axis=1)\n",
    "ap2b = ap2b.sort_values(by=['Department','Total'], ascending=[True,False])\n",
    "ap2b_name = 'ap_op_grp_dept_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by department/supplier/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap2c = ap1a\n",
    "ap2c = ap2c.drop(columns=['Internal ID','Type','Account','Status'])\n",
    "ap2c['Date Created'] = ap2c['Date Created'].dt.strftime('%d-%b-%y')\n",
    "ap2c['Date'] = ap2c['Date'].dt.strftime('%d-%b-%y')\n",
    "ap2c['Due Date/Receive By'] = ap2c['Due Date/Receive By'].dt.strftime('%d-%b-%y')\n",
    "ap2c['Due Date'] = ap2c['Due Date'].dt.strftime('%d-%b-%y')\n",
    "ap2c.set_index(['Department','Name', 'Document Number'],inplace=True)\n",
    "ap2c = ap2c.sort_index(ascending=[True,True,False])\n",
    "ap2c_name = 'ap_op_lst_dept_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by due date/supplier/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap2d = ap1a\n",
    "ap2d = ap2d.drop(columns=['Internal ID','Type','Account','Status'])\n",
    "ap2d = ap2d.groupby(['Due Date','Name', 'Document Number', 'Installment Number'])[['Payment Amount']].sum()\n",
    "ap2d['Cumulative Amount'] = ap2d['Payment Amount'].cumsum()\n",
    "#ap2d.reset_index(level = [1,2,3], inplace=True)\n",
    "#ap2d['Due Date'] = ap2d['Due Date'].dt.strftime('%d-%b-%y')\n",
    "#ap2d = ap2d.drop(columns='Due Date/Receive By')\n",
    "ap2d_name = 'ap_op_lst_duedat_suppl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap2d.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Open bills - Project View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### by project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap3a = ap1a[ap1a['Project Reference'].notna()]\n",
    "ap3a = ap3a.groupby(['Project Reference','Due Date/Receive By'])[['Amount']].sum()\n",
    "ap3a = ap3a.unstack(1)\n",
    "ap3a = ap3a.resample('M', level=1, axis=1).sum()\n",
    "ap3a = ap3a.groupby(['Project Reference']).sum()\n",
    "ap3a.columns = ap3a.columns.strftime('%b-%y')\n",
    "ap3a_name = 'ap_op_grp_proj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### by project/supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap3b = ap1a[ap1a['Project Reference'].notna()]\n",
    "ap3b = ap3b.groupby(['Project Reference','Name','Due Date/Receive By'])[['Amount']].sum()\n",
    "ap3b = ap3b.unstack(2)\n",
    "ap3b = ap3b.resample('M', level=1, axis=1).sum()\n",
    "ap3b.columns = ap3b.columns.strftime('%b-%y')\n",
    "ap3b_name = 'ap_op_grp_proj_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### by project/supplier/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap3c = ap1a[ap1a['Project Reference'].notna()]\n",
    "ap3c = ap3c.groupby(['Project Reference','Name','Document Number','Due Date/Receive By'])[['Amount']].sum()\n",
    "ap3c.reset_index(level = 3, inplace = True)\n",
    "ap3c['Due Date/Receive By'] = ap3c['Due Date/Receive By'].dt.strftime('%d-%b-%y')\n",
    "ap3c_name = 'ap_op_lst_proj_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Weekly payments schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap4a = ap1a\n",
    "ap4a = ap4a.set_index('Due Date/Receive By')\n",
    "ap4a = ap4a.resample('W-SUN', axis=0)['Amount'].sum().reset_index()\n",
    "ap4a = ap4a.rename(columns = {'Due Date/Receive By' : 'Pmt Week Ending'})\n",
    "ap4a = ap4a.set_index('Pmt Week Ending')\n",
    "ap4a_name = 'ap_op_weekly_amt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Open bills - Category View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_lst = pd.DataFrame(ap1b['Account'].unique(), columns = ['Account'])\n",
    "temp_lst['Code'] = temp_lst.Account.str[:4]\n",
    "temp_lst.sort_values('Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary dataframe for category reporting\n",
    "\n",
    "ap5a = ap1b\n",
    "capex = ['5615', '6020']\n",
    "winemaking = ['5523', '5525']\n",
    "prod_purchases = ['3004', '5532', '4045', '2099']\n",
    "hospo = ['2044']\n",
    "ap5a_capex = ap5a.loc[ap5a['Account'].str[:4].isin(capex)]\n",
    "ap5a_prod = ap5a.loc[(ap5a['Account'].str[:4].isin (prod_purchases))]\n",
    "ap5a_winemaking = ap5a.loc[(ap5a['Account'].str[:4].isin (winemaking))]\n",
    "ap5a_hospo = ap5a.loc[(ap5a['Account'].str[:4].isin (hospo))]\n",
    "# ? ap5a_opex = ap5a.loc[~ap5a['Account'].str[:4].isin ([capex,prod_purchases,winemaking,hospo])]\n",
    "ap5a_aggreg_lst = [ap5a_capex, ap5a_prod, ap5a_winemaking, ap5a_hospo]\n",
    "ap5a_aggreg = pd.concat(ap5a_aggreg_lst, keys = ['Capex', 'Production', 'Winemaking', 'Hospitality'])\n",
    "ap5a_aggreg.index.names = ['Group', 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Weekly bills by category (capex, opex, production, winemaking, hospo)\n",
    "\n",
    "ap5b = ap5a_aggreg.groupby(['Group', 'Due Date/Receive By'])[['Amount']].sum()\n",
    "ap5b = ap5b.unstack(1)\n",
    "ap5b = ap5b.resample('W-SUN', level=1, axis=1).sum()\n",
    "ap5b.loc['TOTAL'] = ap5b.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Monthly bills by capex supplier\n",
    "\n",
    "ap5c = ap5a_aggreg.groupby(['Group', 'Name','Due Date/Receive By'])[['Amount']].sum()\n",
    "ap5c = ap5c.reset_index()\n",
    "ap5c = ap5c.loc[ap5c['Group'] == 'Capex']\n",
    "ap5c.set_index(['Group','Name','Due Date/Receive By'], inplace=True)\n",
    "ap5c = ap5c.unstack(2)\n",
    "ap5c = ap5c.resample('M', level=1, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ap5b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Invoices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Open invoices schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar2a = ar1a.pivot_table(index=['Department'], columns=['Due Date/Receive By'], values='Amount', aggfunc='sum')\n",
    "ar2a = ar2a.resample('M', axis=1).sum()\n",
    "ar2a.columns = ar2a.columns.strftime('%b-%y')\n",
    "ar2a['Total'] = ar2a.sum(axis=1)\n",
    "ar2a.loc['TOTAL'] = ar2a.sum(axis=0)\n",
    "ar2a = ar2a.sort_values(by=['Department','Total'], ascending=[True,False])\n",
    "ar2a_name = 'ar_op_grp_by_dept'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### by department/supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar2b = ar1a\n",
    "ar2b = ar2b.pivot_table(index=['Department','Name'], columns='Due Date/Receive By', values='Amount', aggfunc='sum')\n",
    "ar2b = ar2b.resample('M', axis=1).sum()\n",
    "ar2b.columns = ar2b.columns.strftime('%b-%y')\n",
    "ar2b['Total'] = ar2b.sum(axis=1)\n",
    "ar2b = ar2b.sort_values(by=['Department','Total'], ascending=[True,False])\n",
    "ar2b_name = 'ar_op_grp_dept_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### by department/supplier/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar2c = ar1a\n",
    "ar2c = ar2c.drop(columns=['Internal ID','Type','Account','Status'])\n",
    "ar2c['Date Created'] = ar2c['Date Created'].dt.strftime('%d-%b-%y')\n",
    "ar2c['Date'] = ar2c['Date'].dt.strftime('%d-%b-%y')\n",
    "ar2c['Due Date/Receive By'] = ar2c['Due Date/Receive By'].dt.strftime('%d-%b-%y')\n",
    "ar2c.set_index(['Department','Name', 'Document Number'],inplace=True)\n",
    "ar2c = ar2c.sort_index(ascending=[True,True,False])\n",
    "ar2c_name = 'ar_op_lst_dept_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### by due date/supplier/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar2d = ar1a\n",
    "ar2d = ar2d.drop(columns=['Internal ID','Type','Account','Status'])\n",
    "ar2d['Due Date'] = ar2d['Due Date/Receive By'].dt.strftime('%d-%b-%y')\n",
    "ar2d = ar2d.groupby(['Due Date/Receive By','Due Date','Name', 'Document Number'])[['Amount']].sum()\n",
    "ar2d.reset_index(level=0, inplace=True)\n",
    "ar2d = ar2d.drop(columns='Due Date/Receive By')\n",
    "ar2d_name = 'ar_op_lst_duedat_suppl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Weekly payments schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar4a = ar1a\n",
    "ar4a = ar4a.set_index('Due Date/Receive By')\n",
    "ar4a = ar4a.resample('W-SUN', axis=0)['Amount'].sum().reset_index()\n",
    "ar4a = ar4a.rename(columns = {'Due Date/Receive By' : 'Pmt Week Ending'})\n",
    "ar4a = ar4a.set_index('Pmt Week Ending')\n",
    "ar4a_name = 'ar_op_weekly_amt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_output_to_excel_multisheets(reports_list, sheets_list, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report, sheet in zip(reports_list, sheets_list):\n",
    "        report.to_excel(writer, sheet_name = sheet, startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "reports = [ap1, ap2a, ap2b, ap2c, ap2d, ap3a, ap3b, ap3c, ap4a]\n",
    "sheets = ['Export AP DB', ap2a_name, ap2b_name, ap2c_name, ap2d_name, ap3a_name, ap3b_name, ap3c_name, ap4a_name]\n",
    "\n",
    "ap_output_to_excel_multisheets(reports, sheets, 'Cash Flow reports - AP - 2020-10-12.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_output_to_excel_multisheets(reports_list, sheets_list, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report, sheet in zip(reports_list, sheets_list):\n",
    "        report.to_excel(writer, sheet_name = sheet, startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "reports = [ar2a, ar2b, ar2c, ar2d, ar4a]\n",
    "sheets = [ar2a_name, ar2b_name, ar2c_name, ar2d_name, ar4a_name]\n",
    "\n",
    "ar_output_to_excel_multisheets(reports, sheets, 'Cash Flow reports - AR.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beverage Sales Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\joao.melo\\Sutton Group\\Budget FY21 - Documents\\General\\03 - Current Version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the database and aggregated results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the database and excluding unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_excel('Consolidated Model-v4.xlsx', skiprows=3, usecols = 'A:BS', sheet_name='Sales Fcst')\n",
    "# Verify if columns (usecols) appropriate for every new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.drop(columns = ['Channel 3', 'Activity']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting the file into database format and adding required financial information (revenues, COGS, FY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=b.melt(['Range','Colour','Varietal','Market','Channel 1','Channel 2','Unit COGS',\\\n",
    "          'Unit Price'],var_name='Period',value_name='Units',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['Revenue'] = c['Unit Price'] * c['Units']\n",
    "c['COGS'] = c['Unit COGS'] * c['Units']\n",
    "c['Margin'] = c['Revenue'] - c['COGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy20 = c.loc[(c.Period>='2019-08-01') & (c.Period<='2020-07-01'),:]\n",
    "fy21 = c.loc[(c.Period>='2020-08-01') & (c.Period<='2021-07-01'),:]\n",
    "fy22 = c.loc[(c.Period>='2021-08-01') & (c.Period<='2022-07-01'),:]\n",
    "fy23 = c.loc[(c.Period>='2022-08-01') & (c.Period<='2023-07-01'),:]\n",
    "\n",
    "fin_years = [fy20, fy21, fy22, fy23]\n",
    "\n",
    "c = pd.concat(fin_years, keys=['FY20', 'FY21', 'FY22', 'FY23'])\n",
    "\n",
    "c = c.reset_index().drop(columns='level_1').rename(columns={'level_0':'FY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ranges are ',c['Range'].unique())\n",
    "print('Varietals are ',c['Varietal'].unique())\n",
    "print('Markets are ',c['Market'].unique())\n",
    "print('Channels 1 are ',c['Channel 1'].unique())\n",
    "print('Channels 2 are ',c['Channel 2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deprecated code that was used to verify data consistency and add Colour field\n",
    "Testing and fixing inconsistent data\n",
    "\n",
    "Verify if ranges listed below match all the ones in source file\n",
    "\n",
    "whites_lst = ['Sauv Blanc', 'White Mischief', 'Chardonnay', 'Pinot Gris', 'Rose', 'Albarino',\\\n",
    "              'Cider', 'Sauv Blanc - 12x375ml', 'Water']\n",
    "reds_lst = ['Merlot Malbec', 'Malbec Merlot', 'Red', 'Pinot Noir', 'Tennessee Red', 'Lagrein',\\\n",
    "            'Syrah', 'Red - 12x375ml']\n",
    "\n",
    "c['Range']=c['Range'].str.strip()\n",
    "\n",
    "c['Channel 1'] = c['Channel 1'].replace('NZ - Off site', 'NZ - Off Site')\n",
    "\n",
    "c.loc[pd.isnull(c['Channel 1']),'Channel 1'] = c['Market']\n",
    "\n",
    "c.loc[pd.isnull(c['Channel 2']),'Channel 2'] = c['Market']\n",
    "\n",
    "if len(c['Range'].unique())>8:\n",
    "    print('Verify possible typos/duplication/NaN in Range data')\n",
    "if len(c['Varietal'].unique())> (len(whites_lst) + len(reds_lst)):\n",
    "    print('Verify possible typos/duplication/NaN in Varietal data')\n",
    "if len(c['Market'].unique())>4:\n",
    "    print('Verify possible typos/duplication/NaN in Market data')\n",
    "if len(c['Channel 1'].unique())>5:\n",
    "    print('Verify possible typos/duplication/NaN in Channel 1 data')\n",
    "if len(c['Channel 2'].unique())>7:\n",
    "    print('Verify possible typos/duplication/NaN in Channel 2 data')\n",
    "\n",
    "Adding required colour information (reds, whites)\n",
    "\n",
    "reds = c.loc[c['Varietal'].isin(reds_lst)]\n",
    "whites = c.loc[c['Varietal'].isin(whites_lst)]\n",
    "colour = [whites, reds]\n",
    "\n",
    "c = pd.concat(colour, keys=['White','Red'])\n",
    "c = c.reset_index().drop(columns='level_1').rename(columns={'level_0':'Colour'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = c.loc[c['FY'] == 'FY21']\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel = temp_df.groupby(['Range','Channel 2'])[['Revenue','Margin', 'Units']].sum()\n",
    "margin_by_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel['Gross Margin'] = margin_by_channel['Margin'] / margin_by_channel['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel = margin_by_channel[['Gross Margin', 'Units']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel = margin_by_channel.drop(index = ['Homeblock', 'Project X', 'Collectors', 'Blush Crush'], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel = margin_by_channel.sort_index(ascending=True, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_channel.to_excel('Margin by Channel.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly report by Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = c\n",
    "total.name = 'TOTAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_excl_onsite = c.loc[c['Channel 1'] != 'NZ - On Site']\n",
    "total_excl_onsite.name = 'TOTAL EXCL ONSITE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic = c.loc[c['Channel 1'] == 'NZ - Off Site']\n",
    "domestic.name = 'DOMESTIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = c.loc[(c['Market'] != 'NZ') & (c['Market'] != 'China')]\n",
    "export.name = 'EXPORTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = c.loc[c['Market'] == 'China']\n",
    "china.name = 'CHINA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsite = c.loc[c['Channel 1'] == 'NZ - On Site']\n",
    "onsite.name = 'ON SITE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Monthly report by Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_monthly_to_excel_singlesheet(views, sheets, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    row = 2\n",
    "    \n",
    "    for view, name in zip(views, names):\n",
    "        \n",
    "        view = view.groupby(['Period'])[['Units','Revenue','COGS','Margin']].sum()\n",
    "        view = view.T\n",
    "        \n",
    "        fin_order = ['Units', 'Revenue', 'COGS', 'Margin']\n",
    "        view = view.reindex(fin_order)\n",
    "        \n",
    "        view.to_excel(writer, sheet_name = sheets, startrow = row, index_label = name, startcol = 0, float_format = '%.0f')\n",
    "        \n",
    "        row = row + len(view.index) + 3\n",
    "    \n",
    "    writer.save()\n",
    "\n",
    "\n",
    "views = [total, total_excl_onsite, domestic, export, china, onsite]\n",
    "names = ['TOTAL', 'TOTAL EXCL ONSITE', 'DOMESTIC', 'EXPORTS', 'CHINA', 'ON SITE'] # ? why not accepting view.name in index_label?\n",
    "sheets = 'Monthly'\n",
    "segments_monthly_to_excel_singlesheet(views, sheets, 'Beverage Sales Report Monthly.xlsx')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Monthly report by Segment/Range/Colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_by_range_colour_to_excel_singlesheet(views, sheets, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    row = 2\n",
    "    for view in views:\n",
    "        \n",
    "        view = view.groupby(['Range', 'Colour', 'Period'])[['Units','Revenue','COGS','Margin']].sum()\n",
    "        view = view.unstack(2).stack(0)\n",
    "        \n",
    "        range_order = ['Expressions', 'Seasonal', 'Homeblock', 'Collectors', 'Blush Crush', 'Project X', 'X']\n",
    "        colour_order = ['White & Rose', 'Red']\n",
    "        fin_order = ['Units', 'Revenue', 'COGS', 'Margin']\n",
    "        view = view.reindex(range_order, level=0)\n",
    "        view = view.reindex(colour_order, level=1)\n",
    "        view = view.reindex(fin_order, level=2)\n",
    "        view.columns = view.columns.strftime('%b-%y')\n",
    "        \n",
    "        view.to_excel(writer, sheet_name = sheets, startrow = row, startcol = 0, float_format = '%.0f')\n",
    "        \n",
    "        row = row + len(view.index) + 3\n",
    "    \n",
    "    writer.save()\n",
    "\n",
    "views = [total, total_excl_onsite, domestic, export, china, onsite]\n",
    "sheets = 'Monthly'\n",
    "segments_by_range_colour_to_excel_singlesheet(views, sheets, 'Beverage Sales Report by Range-Colour.xlsx')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes_by_market = c.groupby(['FY','Market'])['Units'].sum()\n",
    "\n",
    "volumes_by_market = volumes_by_market.unstack(0).stack().unstack(0)\n",
    "\n",
    "volumes_by_market['Total'] = volumes_by_market.sum(axis=1, skipna=True)\n",
    "\n",
    "revenues_by_market = c.groupby(['FY','Market'])['Revenue'].sum()\n",
    "\n",
    "revenues_by_market = revenues_by_market.unstack(0).stack().unstack(0)\n",
    "\n",
    "revenues_by_market['Total'] = revenues_by_market.sum(axis=1, skipna=True)\n",
    "\n",
    "margin_by_market = c.groupby(['FY','Market'])['Margin'].sum()\n",
    "\n",
    "margin_by_market = margin_by_market.unstack(0).stack().unstack(0)\n",
    "\n",
    "margin_by_market['Total'] = margin_by_market.sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes_by_product = c.groupby(['FY','Range', 'Varietal'])['Units'].sum()\n",
    "\n",
    "volumes_by_product = volumes_by_product.unstack(0).stack().unstack(0)\n",
    "\n",
    "volumes_by_product['Total'] = volumes_by_product.sum(axis=1, skipna=True)\n",
    "\n",
    "revenues_by_product = c.groupby(['FY','Range', 'Varietal'])['Revenue'].sum()\n",
    "\n",
    "revenues_by_product = revenues_by_product.unstack(0).stack().unstack(0)\n",
    "\n",
    "revenues_by_product['Total'] = revenues_by_product.sum(axis=1, skipna=True)\n",
    "\n",
    "margin_by_product = c.groupby(['FY','Range', 'Varietal'])['Margin'].sum()\n",
    "\n",
    "margin_by_product = margin_by_product.unstack(0).stack().unstack(0)\n",
    "\n",
    "margin_by_product['Total'] = margin_by_product.sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brix China Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'P:\\Finance\\6-Brix China\\Financials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_files = list(glob.glob('*P&L.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_month_rep = [m for m in dir_files]\n",
    "reps = [pd.read_excel(month_rep, skiprows=2, nrows=16) for month_rep in all_month_rep]\n",
    "df_names=[]\n",
    "for month_rep in all_month_rep:\n",
    "    name=month_rep[:3]\n",
    "    df_names.append(name)\n",
    "\n",
    "a=zip(reps,df_names)\n",
    "\n",
    "for rep,df_name in a:\n",
    "    rep['Source']=df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mult_reps_mult_sheets(reports, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report in reports:\n",
    "        report.to_excel(writer, sheet_name = str(df_names[n]), startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "mult_reps_mult_sheets(reps, 'Output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mult_reps_single_sheet(reports, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    row=1\n",
    "    for report in reports:\n",
    "        report.to_excel(writer, sheet_name = 'Single Sheet', startrow = row, startcol = 0)\n",
    "        n+=1\n",
    "        row=row+len(report)+3\n",
    "    writer.save()\n",
    "\n",
    "mult_reps_single_sheet(reps, 'Output.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brix Revenues, Costs and Production Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as op\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\joao.melo\\Sutton Group\\Budget FY21 - Documents\\Forecasts\\01-Sep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = pd.ExcelFile('CoPack - FY21 Budget vs Fcst 09.09.20.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the volumes database (filtered by 'in budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_excel(src_file, skiprows=4, sheet_name='Combined Detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a1.drop(columns=['FY20 Val', 'FY21 Val', 'FY22 Val', 'FY23 Val',\n",
    "       'Aug-20 Val', 'Sep-20 Val', 'Oct-20 Val', 'Nov-20 Val', 'Dec-20 Val',\n",
    "       'Jan-21 Val', 'Feb-21 Val', 'Mar-21 Val', 'Apr-21 Val', 'May-21 Val',\n",
    "       'Jun-21 Val', 'Jul-21 Val']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.melt(['DEPARTMENT', 'PROD_ID', 'CUST_ID', 'PROD_PLAN_ID', 'PRODUCTION_ID', 'Customer',\\\n",
    "       'Average_Price', 'Product_Category', 'Type', 'Status', 'Included_in_Budget',\\\n",
    "       'Long_Term_Demand', 'Inner_Packaging/Multi label', 'Blending',\\\n",
    "       'Pasteurised', 'Run_Size', 'Vessel_Type', 'Vessel_Size',\\\n",
    "       'Vessel_Vol_(ml)', 'Baseline_Vol', 'Growth_FY1-FY2', 'Growth_FY2-FY3','FY20', 'FY21', 'FY22', 'FY23'], var_name = 'Period', value_name = 'Units', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.Period = '01-' + b.Period.astype(str)\n",
    "\n",
    "b.Period = pd.to_datetime(b.Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['Revenue'] = b['Average_Price'] * b['Units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy20 = b.loc[(b.Period>='2019-08-01') & (b.Period<='2020-07-01'),:]\n",
    "fy21 = b.loc[(b.Period>='2020-08-01') & (b.Period<='2021-07-01'),:]\n",
    "fy22 = b.loc[(b.Period>='2021-08-01') & (b.Period<='2022-07-01'),:]\n",
    "fy23 = b.loc[(b.Period>='2022-08-01') & (b.Period<='2023-07-01'),:]\n",
    "\n",
    "fin_years = [fy20, fy21, fy22, fy23]\n",
    "\n",
    "b = pd.concat(fin_years, keys=['FY20', 'FY21', 'FY22', 'FY23'])\n",
    "\n",
    "b = b.reset_index().drop(columns='level_1').rename(columns={'level_0':'FY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b[b.Included_in_Budget == 'Yes']\n",
    "b = b[b.Type == 'Forecast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production configurations and parameters table (excl. non programmed items - e.g. Kegs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production Database (e.g. excludes volumes not used in production planning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = b.loc[b['PROD_PLAN_ID'] != 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production Parameters Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = pd.read_excel(src_file, skiprows=1, usecols='C:O', nrows=8,  sheet_name='Production - CP')\n",
    "d0 = d0.dropna(axis=1)\n",
    "d0 = d0.set_index('Parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0t = d0.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d1 = pd.DataFrame({'PROD_PLAN_ID':c0['PROD_PLAN_ID'].unique()})\n",
    "d1 = d1.set_index('PROD_PLAN_ID')\n",
    "d1 = d1.sort_values('PROD_PLAN_ID')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers volume per configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_cust_1 = c0.loc[c0['FY'] == 'FY21']\n",
    "top5_cust_1 = top5_cust_1.groupby(['PROD_PLAN_ID','Customer'])[['Units']].sum()\n",
    "top5_cust_1.sort_values(['PROD_PLAN_ID','Units'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_vols = c0.groupby(['PROD_PLAN_ID', 'FY', 'Period'])[['Units']].sum()\n",
    "prod_vols = prod_vols.unstack(0)\n",
    "prod_vols['Period Total'] = prod_vols.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_hours = prod_vols.div(d0.iloc[6], level=1, axis=1)\n",
    "prod_hours_total = prod_hours.sum(axis=1)\n",
    "prod_hours['Period Total'] = prod_hours.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_price = c0.groupby(['PROD_PLAN_ID', 'FY', 'Period'])[['Units', 'Revenue']].sum()\n",
    "unit_price['Average Price'] = unit_price['Revenue'] / unit_price['Units']\n",
    "unit_price = unit_price.drop(columns = ['Units', 'Revenue'])\n",
    "unit_price = unit_price.unstack(0)\n",
    "\n",
    "avg_unit_price = c0.groupby(['FY', 'Period'])[['Units', 'Revenue']].sum()\n",
    "avg_unit_price['Avg Unit Price'] = avg_unit_price['Revenue'] / avg_unit_price['Units']\n",
    "avg_unit_price = avg_unit_price.drop(columns = ['Revenue', 'Units'])\n",
    "\n",
    "unit_price['Avg Unit Price'] = avg_unit_price['Avg Unit Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuf_cost = pd.read_excel(src_file, skiprows=1, usecols='D:Y', sheet_name='Manuf Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_cost = prod_hours.div(prod_hours_total, level=1, axis=0) / prod_vols\n",
    "unit_cost = unit_cost.mul(manuf_cost['TOTAL MANUFACTURING COST'].values, axis=0)\n",
    "unit_cost = unit_cost.rename(columns = {'Period Total' : 'Avg Unit Cost'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dir_cost = prod_hours.div(prod_hours_total, level=1, axis=0) / prod_vols\n",
    "unit_dir_cost = unit_dir_cost.mul(manuf_cost['TOTAL DIRECT LABOUR COST'].values, axis=0)\n",
    "unit_dir_cost = unit_dir_cost.rename(columns = {'Period Total' : 'Avg Unit Cost'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_margin = unit_price.sub(unit_cost.values, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dir_margin = unit_price.sub(unit_dir_cost.values, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_margin = unit_margin.mul(prod_vols.values)\n",
    "nom_margin['Period Total'] = nom_margin.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg unit direct margin per FY\n",
    "\n",
    "aum_lst = []\n",
    "for fy in ['FY20', 'FY21', 'FY22', 'FY23']:\n",
    "    m = ((unit_dir_margin['Avg Unit Price'].loc[fy].mul(prod_vols['Period Total'].loc[fy])).sum())/(prod_vols['Period Total'].loc[fy].sum())\n",
    "    aum_lst.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Volumes, Revenues and Avg Price per product per month DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding kegs and Brix volumes and None IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = b\n",
    "c1 = c1[~c1['PROD_PLAN_ID'].isin(['WNKL','None'])]\n",
    "c1 = c1[c1['CUST_ID'] != 'BRIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenues by Period (Excludes kegs and Brix volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2a = c1\n",
    "c2a = c2a.groupby(['Period'])[['Revenue']].sum()\n",
    "c2a.index = prod_vols.index\n",
    "revenue_by_period = c2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenues by Production Plan ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2b = c1\n",
    "c2b = c2b.groupby(['FY','Period','PROD_PLAN_ID'])[['Revenue']].sum()\n",
    "c2b = c2b.unstack(2)\n",
    "revenue_by_prod_plan_id = c2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vols = prod_vols.loc['FY21']\n",
    "annual_vols = annual_vols.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_prod_hours = prod_hours.loc['FY21'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_revenues = revenue_by_prod_plan_id.loc['FY21'].sum()\n",
    "annual_revenues['Period Total'] = annual_revenues.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_dir_labour_cost = unit_dir_cost.loc['FY21'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production Analysis Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d0t\n",
    "d1['Production Hours FY21'] = p1\n",
    "d1['Production Volume FY21'] = ''\n",
    "d1['Revenues FY21'] = ''\n",
    "d1['Avg Price FY21'] = ''\n",
    "d1['Revenue per Hour FY21'] = ''\n",
    "d1['Direct Margin per Hour FY21'] = ''\n",
    "d1['Total Direct Margin FY21'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d0t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = prod_hours.loc['FY21'].drop(columns='Period Total').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = prod_vols.loc['FY21'].drop(columns='Period Total').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = revenue_by_prod_plan_id.loc['FY21'].sum()\n",
    "p3.index = p2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = p3/p1\n",
    "p5.index = p2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p6 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Production Hours FY21' : p1, 'Production Volume FY21' : p2, \\\n",
    "        'Revenues FY21' : p3, 'Avg Price FY21' : p4, 'Revenue per Hour FY21' : p5, \\\n",
    "       'Direct Margin per Hour FY21' : p6, 'Total Direct Margin FY21' : p7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Report - Parameters per Hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Report - Parameters per Unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Report - Production Configuration Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry Goods Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgdb = pd.read_excel('Dry Goods Parameters.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_items_cust.to_excel('DG Items by Customer.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_items_cust = dgdb.groupby(['CUST_ID','Customer','Item'])['DG_Unit_Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_unit_price_cust = dgdb.groupby(['CUST_ID','Customer'])['DG_Unit_Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_rev_db = pd.merge(b,dg_unit_price_cust, on='CUST_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_rev_db['DG Revenue'] = dg_rev_db['Units'] * dg_rev_db['DG_Unit_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_rev = dg_rev_db.groupby(['Customer'])['DG Revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_rev_db.to_excel('DG Revenues.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_excel_multisheets(reports_list, sheets_list, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report, sheet in zip(reports_list, sheets_list):\n",
    "        report.to_excel(writer, sheet_name = sheet, startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "reports = [production_parameters, prod_vols, prod_hours, unit_price, manuf_cost, unit_cost, unit_margin, nom_margin, revenues]\n",
    "sheets = ['production_parameters', 'prod_vols', 'prod_hours', 'unit_price', 'manuf_cost', 'unit_cost', 'unit_margin', 'nom_margin', 'revenues']\n",
    "\n",
    "output_to_excel_multisheets(reports, sheets, 'Sales and Production Planning- v4.2.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as op\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Card users list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv , map , format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_users = pd.read_csv ('card_users.csv') # td Adapt to read csv from proper file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_users['Card_ID'] = card_users['Card_ID'].map('{:04.0f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank statement treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob, df.drop, applying math formula, df.loc, input, pd.to_datetime, datetime.strftime, df.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob('TransHist*.csv'):\n",
    "    bank_statement = pd.read_csv (file) # td Adapt to read csv without specific name of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement = bank_statement.drop(bank_statement.columns[[7]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement.Amount = bank_statement.Amount * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement = bank_statement.loc[bank_statement['Tran Type'] != 'PAY', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Drop_Date = input('Type date to exclude') # td Add possibility to not exclude any date or to exclude more than one date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement = bank_statement.loc[bank_statement['Date'] != Drop_Date, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_statement.Amount.sum()) # td Add ability to capture target amount and match csv file sum with it + Format 2 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement['Reference'] = bank_statement['Reference'].map('{:.0f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement['Date'] = pd.to_datetime(bank_statement['Date']).dt.strftime('%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_statement['Card_ID'] = bank_statement['Reference'].str[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.merge, create new column, df.to_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolid_1 = pd.merge(bank_statement, card_users, how='left', on='Card_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolid_1['Transaction_ID'] = consolid_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolid_1.to_excel('C:\\\\Users\\\\joao.melo\\\\Downloads\\\\2020-04\\\\consolid_1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual reports prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.drop_duplicates, df.sort_values, df.reset_index, for loop, op.load_workbook, df.active (sheet), ws.column_dimensions (width), ws.row_dimensions (in for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Employees = consolid_1['Employee'].drop_duplicates().sort_values().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Employee in Employees:\n",
    "    individual_report = consolid_1[(consolid_1.Employee == Employee)]\n",
    "    individual_report = (individual_report[['Date', 'Amount', 'Payee', 'Card_ID']])\n",
    "    individual_report['Description'] = ''\n",
    "    individual_report.to_excel(str(Employee) + '-card.xlsx', index_label = 'Transaction_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With iter_rows\n",
    "\n",
    "for Employee in Employees:\n",
    "    individual_report_xl = op.load_workbook(str(Employee) + '-card.xlsx')\n",
    "    report_sheet = individual_report_xl.active\n",
    "    for row in report_sheet.iter_rows(2,None):\n",
    "        report_sheet.row_dimensions.height=20\n",
    "    report_sheet.column_dimensions['B'].width = 15\n",
    "    report_sheet.column_dimensions['C'].width = 15\n",
    "    report_sheet.column_dimensions['D'].width = 30\n",
    "    report_sheet.column_dimensions['E'].width = 10\n",
    "    report_sheet.column_dimensions['F'].width = 45\n",
    "#    for i in range(0,30):\n",
    "#        report_sheet.row_dimensions[i+1].height=20\n",
    "    individual_report_xl.save(str(Employee) + '-card.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With for loop\n",
    "\n",
    "for Employee in Employees:\n",
    "    individual_report_xl = op.load_workbook(str(Employee) + '-card.xlsx')\n",
    "    report_sheet = individual_report_xl.active\n",
    "    report_sheet.column_dimensions['B'].width = 15\n",
    "    report_sheet.column_dimensions['C'].width = 15\n",
    "    report_sheet.column_dimensions['D'].width = 30\n",
    "    report_sheet.column_dimensions['E'].width = 10\n",
    "    report_sheet.column_dimensions['F'].width = 45\n",
    "    for i in range(0,30):\n",
    "        report_sheet.row_dimensions[i+1].height=20\n",
    "    individual_report_xl.save(str(Employee) + '-card.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a practical way to autofit column widths as this is quite a long code for not so much value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emailing individual reports to card users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_email = 'joao.melo@brix.co.nz'\n",
    "rec_email = 'joao.melo@brix.co.nz'\n",
    "subject = 'Testing Python email'\n",
    "password = 'TheL0dg3!!'\n",
    "message = 'Subject: Testing Python email.\\nHey, this is an email test using Python'\n",
    "\n",
    "server = smtplib.SMTP('smtp.office365.com', 587)\n",
    "type(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.ehlo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.starttls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.login(sender_email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Login success')\n",
    "server.sendmail(sender_email, rec_email, message)\n",
    "print('Email has been sent to ', rec_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating updated individual reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob, loop in glob, pd.concat (with loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individ_reports = [i for i in glob.glob('*-card.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_individ_reports = pd.concat([pd.read_excel(f) for f in all_individ_reports], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_individ_reports.to_excel('Combined_Individual_Reports.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging individual report updates with Consolidated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolid_2 = (pd.merge(consolid_1, combined_individ_reports[['Transaction_ID', 'Description']],\n",
    "            on='Transaction_ID', how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolid_2.to_excel('Consolidated_pre_coding.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as op\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projects Capex Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_excel('Capex bills.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=a.drop(columns='Comments')\n",
    "a=a.melt(['Suppliers'], var_name='Period', value_name='Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.loc[a.Period>='2020-06-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=b.groupby(['Suppliers','Period'])['Amount'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=c.unstack('Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Total']=d.loc[:,'2020-06-01':'2020-09-01'].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=d.sort_values('Total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.to_excel('Capex bills out.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Charges - DGs and FGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'P:\\Finance\\0-Routine Activities\\0-Invoicing\\01 Aug 2020\\Storage\\TWE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stor_a = pd.read_excel('TWE Storage 29072020-01092020.xlsx', skiprows = 6, sheet_name = ['W1','W2','W3','W4','W5','Excluded Stock','Pallet data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture information from reports extracted into spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = stor_a['W1']\n",
    "w2 = stor_a['W2']\n",
    "w3 = stor_a['W3']\n",
    "w4 = stor_a['W4']\n",
    "w5 = stor_a['W5']\n",
    "excl = stor_a['Excluded Stock']\n",
    "pallet_conv = stor_a['Pallet data']\n",
    "\n",
    "weeks = [w1,w2,w3,w4,w5]\n",
    "\n",
    "w_all = pd.concat(weeks, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare relevant items and volumes to be charged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [w[(w['Item'].str[3] != 'L') & (w['Item'].str[3] != 'P') & \\\n",
    "           (w['Product Owner'] == 'CUS000404 Treasury Wine Estates') \\\n",
    "           & (w['Ending Inv Qty On-hand'] != 0)] for w in weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [w.fillna(0) for w in weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [w.groupby(['Week','Item Type: Long Name','Item','Display Name','Units per Pallet','Pallet Type']) \\\n",
    "         [['Ending Inv Qty On-hand']].mean().reset_index() for w in weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twe_w_all = pd.concat(weeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of item to exclude (recently produced items with free storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type correct initial date for period being charged + verify number of weeks to charge\n",
    "ini_date = '29-07-20'\n",
    "ini_date_w1 = dt.datetime.strptime(ini_date, \"%d-%m-%y\")\n",
    "end_date_w1 = ini_date_w1 + dt.timedelta(days=7)\n",
    "end_date_w2 = ini_date_w1 + dt.timedelta(days=14)\n",
    "end_date_w3 = ini_date_w1 + dt.timedelta(days=21)\n",
    "end_date_w4 = ini_date_w1 + dt.timedelta(days=28)\n",
    "end_date_w5 = ini_date_w1 + dt.timedelta(days=35)\n",
    "\n",
    "end_date_all = [end_date_w1,end_date_w2,end_date_w3,end_date_w4,end_date_w5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_w1 = excl.loc[(excl['Transaction Date']>=ini_date_w1) & (excl['Transaction Date']<=end_date_w1),:]\n",
    "excl_w2 = excl.loc[(excl['Transaction Date']>end_date_w1) & (excl['Transaction Date']<=end_date_w2),:]\n",
    "excl_w3 = excl.loc[(excl['Transaction Date']>end_date_w2) & (excl['Transaction Date']<=end_date_w3),:]\n",
    "excl_w4 = excl.loc[(excl['Transaction Date']>end_date_w3) & (excl['Transaction Date']<=end_date_w4),:]\n",
    "excl_w5 = excl.loc[(excl['Transaction Date']>end_date_w4) & (excl['Transaction Date']<=end_date_w5),:]\n",
    "\n",
    "excl_all = [excl_w1,excl_w2,excl_w3,excl_w4,excl_w5]\n",
    "\n",
    "excl_all = pd.concat(excl_all, keys=['W1','W2','W3','W4','W5'])\n",
    "excl_all = excl_all.reset_index().drop(columns='level_1').rename(columns={'level_0':'Week'})\n",
    "excl_all = excl_all.groupby(['Week','Product Owner','Item Code'])[['QTY Completed']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_twe = (excl_all.loc[excl_all['Product Owner'] == 'CUS000404 Treasury Wine Estates']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all relevant information into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csldt_twe = pd.merge(twe_w_all,excl_twe[['Week','Item Code','QTY Completed']],left_on=['Week','Item'], \\\n",
    "                     right_on=['Week','Item Code'],how='left').drop(columns='Item Code').fillna(0)\n",
    "csldt_twe['Units Charged'] = csldt_twe['Ending Inv Qty On-hand'] - csldt_twe['QTY Completed']\n",
    "csldt_twe['Pallets Charged'] = csldt_twe['Units Charged'].div(csldt_twe['Units per Pallet'], \\\n",
    "                                                                  fill_value=0).apply(np.ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce output reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twe_summ_pallets = csldt_twe.groupby(['Week','Item Type: Long Name','Pallet Type'])['Pallets Charged'].sum()\n",
    "twe_summ_pallets = twe_summ_pallets.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twe_summ_units = csldt_twe.groupby(['Week','Item Type: Long Name','Pallet Type'])['Units Charged'].sum()\n",
    "twe_summ_units = twe_summ_units.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twe_exceptions_db = csldt_twe.loc[csldt_twe['Units per Pallet']<=0,:]\n",
    "twe_exceptions_items = twe_exceptions_db.groupby(['Item'])[['Units Charged']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summaries_single_sheet(reports, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    row=1\n",
    "    for report in reports:\n",
    "        report.to_excel(writer, sheet_name = 'Single Sheet', startrow = row, startcol = 0)\n",
    "        n+=1\n",
    "        row=row+len(report)+5\n",
    "    writer.save()\n",
    "reps = [twe_summ_pallets,twe_summ_units,twe_exceptions_items]\n",
    "summaries_single_sheet(reps, 'TWE Storage reports - 2020-09-01.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twe_output_to_excel_multisheets(reports_list, sheets_list, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report, sheet in zip(reports_list, sheets_list):\n",
    "        report.to_excel(writer, sheet_name = sheet, startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "reports = [csldt_twe,twe_exceptions_db]\n",
    "sheets = ['TWE database','Exceptions database']\n",
    "\n",
    "twe_output_to_excel_multisheets(reports, sheets, 'TWE Storage reports - 2020-09-01-2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customers excluding TWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating selected data into single dataframe\n",
    "\n",
    "inv_sel = [w31,w32,w33,w34,w35]\n",
    "\n",
    "for w in inv_sel:\n",
    "    w['Stored Units'] = w[['Beginning Inv Qty On-hand','Ending Inv Qty On-hand']].min(axis=1)\n",
    "\n",
    "stor_all = pd.concat(inv_sel, keys=['w31','w32','w33','w34','w35'], copy = True)\\\n",
    "            .reset_index().rename(columns={'level_0':'Week'}).drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Units conversion and storage charging parameters (master data) preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = stor_a['Master Data and Conversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Cost Categories that do not raise storage charges\n",
    "\n",
    "excluded_items = ['Dry Goods- Labels','Raw Materials','Pallet', 'Wine Batch', 'Additives',\\\n",
    "            'Dry Goods- Others', 'Beverage Batch','Rework Item']\n",
    "excluded_customers = ['CUS000284 Brix & Co Limited', 'CUS000424 Brix - Production', 'CUS000399 SKU Ltd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data in column used for conversion, so it can be of the float type (as opposed to object)\n",
    "# NOTE: Used to clean data first time. Deactivated now because it will raise an error since there's no more str in the data\n",
    "\n",
    "#conv['Units to Pallet'] = conv['Units to Pallet'].replace({'TBC':0,'':0}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying items between chargeable and non chargeable ones for storage\n",
    "\n",
    "# conv['Storage Chargeable'] = conv['Cost Category'].apply(lambda x: 'No' if x in(excluded_items) else 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base data preparation for period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting tabs that will be used in calculation of storage charges\n",
    "\n",
    "w31 = stor_a['Week 31'].copy()\n",
    "w32 = stor_a['Week 32'].copy()\n",
    "w33 = stor_a['Week 33'].copy()\n",
    "w34 = stor_a['Week 34'].copy()\n",
    "w35 = stor_a['Week 35'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating selected data into single dataframe\n",
    "\n",
    "inv_sel = [w31,w32,w33,w34,w35]\n",
    "\n",
    "for w in inv_sel:\n",
    "    w['Stored Units'] = w[['Beginning Inv Qty On-hand','Ending Inv Qty On-hand']].min(axis=1)\n",
    "\n",
    "stor_all = pd.concat(inv_sel, keys=['w31','w32','w33','w34','w35'], copy = True)\\\n",
    "            .reset_index().rename(columns={'level_0':'Week'}).drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding conversion values from Conversion (master data table) into dataframe\n",
    "\n",
    "stor_all = stor_all.merge(conv[['Name','Pallet Conversion Units','Domestic/Export', 'Cost Category','Chep/Non-Chep', 'Supplier','Storage Chargeable']], how='left', left_on='Item', right_on='Name')\n",
    "\n",
    "# Calculating the number of pallets stored based on units stored and conversion parameters to pallets\n",
    "\n",
    "stor_all['Pallets Stored'] = stor_all['Stored Units'].div(stor_all['Pallet Conversion Units'],fill_value=0)\n",
    "stor_all = stor_all.replace([np.inf,-np.inf], np.nan)\n",
    "stor_all_roundup = stor_all.copy()\n",
    "stor_all_roundup['Pallets Stored'] = stor_all['Pallets Stored'].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_gen = ['w31', 'w32', 'w33', 'w34', 'w35']\n",
    "stor_gen = stor_all_roundup.loc[stor_all['Product Owner'] != 'CUS000404 Treasury Wine Estates']\n",
    "stor_gen = stor_gen.loc[stor_gen['Week'].isin(weeks_gen)]\n",
    "\n",
    "weeks_twe = ['w31', 'w32', 'w33', 'w34', 'w35']\n",
    "stor_twe = stor_all_roundup.loc[stor_all['Product Owner'] == 'CUS000404 Treasury Wine Estates']\n",
    "stor_twe = stor_twe.loc[stor_twe['Week'].isin(weeks_twe)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference data verification (comparison) by Item Type (e.g. glass, cartons, caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verif = stor_all_roundup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verif = data_verif.loc[~data_verif['Cost Category'].isin(excluded_items)]\n",
    "data_verif = data_verif.loc[~data_verif['Product Owner'].isin(excluded_customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verif = data_verif.groupby(['Cost Category', 'Item'])[['Stored Units','Pallet Conversion Units']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verif['Check Parameters'] = np.where((data_verif['Stored Units'] >0) & (data_verif['Pallet Conversion Units'] == 0),'Verify',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_summ_gen = stor_gen.loc[stor_gen['Storage Chargeable'] == 'Yes'].copy()\n",
    "\n",
    "charge_summ_gen = charge_summ_gen.groupby(['Product Owner', 'Item Type: Long Name','Week'])\\\n",
    "            [['Pallets Stored']].sum().fillna(0).unstack([1,2])\n",
    "charge_summ_gen['Total Pallets'] = charge_summ_gen['Pallets Stored'].sum(axis=1)\n",
    "\n",
    "charge_summ_gen = charge_summ_gen.sort_values(by='Total Pallets', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_summ_twe = stor_twe.loc[stor_all_roundup['Storage Chargeable'] == 'Yes'].copy()\n",
    "\n",
    "charge_summ_twe = charge_summ_twe.groupby(['Chep/Non-Chep','Item Type: Long Name','Week'])\\\n",
    "            [['Pallets Stored']].sum().fillna(0).unstack([0,1])\n",
    "charge_summ_twe['Total Pallets'] = charge_summ_twe['Pallets Stored'].sum(axis=1)\n",
    "\n",
    "charge_summ_twe = charge_summ_twe.sort_values(by='Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_detail = stor_all_roundup.loc[stor_all['Storage Chargeable'] == 'Yes'].copy()\n",
    "charge_detail = charge_detail.groupby(['Product Owner', 'Item Type: Long Name','Item','Week'])\\\n",
    "            [['Stored Units','Pallets Stored']].sum().fillna(0).unstack(3)\n",
    "#charge_detail['Total Pallets'] = charge_detail['Pallets Stored'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_summ_twe.loc['Total'] = charge_summ_twe.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storage_output_to_excel_multisheets(reports_list, sheets_list, file_name):\n",
    "    writer = pd.ExcelWriter(file_name)\n",
    "    n=0\n",
    "    for report, sheet in zip(reports_list, sheets_list):\n",
    "        report.to_excel(writer, sheet_name = sheet, startrow = 0, startcol = 0)\n",
    "        n+=1\n",
    "    writer.save()\n",
    "\n",
    "reports = [charge_summ_gen, charge_summ_twe, charge_detail, data_verif]\n",
    "sheets = ['Summary Report General', 'Summary Report TWE','Detailed Report','Data Verification']\n",
    "\n",
    "storage_output_to_excel_multisheets(reports, sheets, 'Storage Charges Weeks 31-35.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful snipets of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indicator of values not equal to variable\n",
    "c.ne(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values using IF statements or based on conditions\n",
    "\n",
    "apx['Internal ID'] = apx['Entered to Due'].apply(lambda x: 'Lommen' if x==16 else 'Pakka')\n",
    "\n",
    "apx.loc[apx['Entered to Due'] == 16, 'Internal ID'] = 'Penga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce an aggregation operation (e.g. sum) in same shape as original dataframe\n",
    "\n",
    "total_order = a_fy2.groupby('ID')[['FY20']].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List duplicates in dataframe\n",
    "a_fy2.loc[a_fy2['ID'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate dataframe into two by defined criteria\n",
    "b1 = b[b['Market']=='China']\n",
    "b2 = b.drop(b1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder from which python is being executed\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! df.index.sortlevel(level=[0,1], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using date of TODAY\n",
    "#ap1a = ap1[(ap1['Status']=='Open') & (ap1['Due Date/Receive By']>dt.datetime.today())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV import - replacing undesired characters\n",
    "# ! manuf_cost1['TOTAL'] = manuf_cost1['TOTAL'].str.replace(',','')\n",
    "# ! manuf_cost1['TOTAL'] = manuf_cost1['TOTAL'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by type\n",
    "production_hours = volumes.select_dtypes(exclude=['object','datetime']).div(machine_output).combine_first(volumes)[volumes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renaming columns with values from a row of data\n",
    "c1.columns = c1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining text with data output\n",
    "for i in range(0,4):\n",
    "    print('Revenue FY2'+str(i)+' is '+ str(b[b.FY == 'FY2'+str(i)].Revenue.sum()) + \\\n",
    "          ' and Volume is ' + str(b[b.FY == 'FY2'+str(i)].Units.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Order by categorical data\n",
    "\n",
    "# When index\n",
    "\n",
    "order = ['In Negotiations', 'Existing', 'In Discussion']\n",
    "b.set_index(['Status'])\n",
    "b.reindex(order)\n",
    "\n",
    "# When column\n",
    "\n",
    "order = ['In Negotiations', 'Existing', 'In Discussion'] # these are values already in the 'Status' field\n",
    "b['Status'] = pd.Categorical(b['Status'], categories = order)\n",
    "b=b.sort_values(by='Status')\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Duplicate / repeat lines of dataframe\n",
    "\n",
    "# using np.repeat\n",
    "newdf = pd.DataFrame(np.repeat(df.values,3,axis=0)) #3 is number of times to repeat\n",
    "newdf.columns = df.columns\n",
    "\n",
    "# using pd.concat\n",
    "dic = [c,c,c]\n",
    "d = pd.concat(dic, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "\n",
    "\"\"\"\n",
    "two_dec_list = ['V19 COGS', 'V19 Price']\n",
    "# set ALL float columns to '${:,.2f}' formatting (including the percentage)\n",
    "format_dict = {col_name: '${:,.2f}' for col_name in two_dec_list}\n",
    "# override the percentage column\n",
    "format_dict['Units'] = '{:,.0f}'\n",
    "format_dict['Revenue'] = '${:,.0f}'\n",
    "format_dict['COGS'] = '${:,.0f}'\n",
    "format_dict['Margin'] = '${:,.0f}'\n",
    "#format_dict['Period'] = '{%b-%y}'\n",
    "\n",
    "onsite = onsite.style.format(format_dict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with styling and formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['Margin %']=(total['Revenue']/total['COGS']-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_styled = total.style\\\n",
    "    .apply(lambda x: ['background:red' if x < 500 else 'background:green' for x in total.Revenue], axis=0)\\\n",
    "    .applymap(lambda x: 'background-color: %s' % 'red' if x <10 else 'background-color: %s' % 'green', subset=['V19 Price','V19 COGS'])\\\n",
    "    .applymap(lambda x: 'background-color: %s' % 'red' if x <1000 else 'background-color: %s' % 'green', subset=['Revenue'])\\\n",
    "    .format({'V19 COGS': '${:20,.2f}'})\\\n",
    "    .format({'V19 Price': '${:20,.2f}'})\\\n",
    "    .format({'Margin %': '{:.2%}'})\\\n",
    "    .format({'Period': '{:%d-%b-%y}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_styled=op.load_workbook('Beverage Sales Report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=rep_styled['Monthly (v1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary style classes\n",
    "from openpyxl.styles import Font, Color, Alignment, Border, Side, colors\n",
    "\n",
    "from openpyxl.styles import NamedStyle\n",
    "\n",
    "# Let's create a style template for the header row\n",
    "header = NamedStyle(name=\"header2\")\n",
    "header.font = Font(bold=True)\n",
    "header.border = Border(bottom=Side(border_style=\"thin\"))\n",
    "header.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "# Now let's apply this to all first row (header) cells\n",
    "header_row = ws[2]\n",
    "for cell in header_row:\n",
    "    cell.style = header\n",
    "\n",
    "rep_styled.save(filename=\"Styled Bev Sales Reports.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Python Guide to Working with Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=['Honda','Nissan','Triumph','Holden']\n",
    "Model=['CRV','Leaf','Tiger','Barina']\n",
    "Type=['Car','Car','Moto','Car']\n",
    "Wheels={'Car':4,'Moto':2}\n",
    "Price=[23000,43000,23000,9000]\n",
    "\n",
    "columns=['Brand','Model','Type','Price']\n",
    "a=zip(Brand,Model,Type,Price)\n",
    "\n",
    "b=pd.DataFrame(a, columns=columns)\n",
    "\n",
    "b['Wheels']=b['Type'].map(Wheels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = [c,c,c]\n",
    "d = pd.concat(dic, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[b.Brand.str.contains('ss|de')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RealPython - A Guide to Excel Spreadsheets in Python With openpyxl - Amazon database example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=op.load_workbook('reviews-sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=wb.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['A1'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in ws.iter_rows(1,1,values_only=True):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for value in ws.iter_rows(2,None,4,7, values_only=True):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {}\n",
    "\n",
    "for row in ws.iter_rows(2,None,4,7, values_only=True):\n",
    "    product_id=row[0]\n",
    "    product = {'parent': row[1],\n",
    "              'title': row[2],\n",
    "              'category': row[3]}\n",
    "    products[product_id] = product\n",
    "\n",
    "print(json.dumps(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in ws[1]:\n",
    "    print(cell.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "from classes import Product, Review\n",
    "from mapping import PRODUCT_ID, PRODUCT_PARENT, PRODUCT_TITLE, PRODUCT_CATEGORY, REVIEW_DATE, REVIEW_ID, \\\n",
    "                    REVIEW_CUSTOMER, REVIEW_STARS, REVIEW_HEADLINE, REVIEW_BODY\n",
    "\n",
    "wb = load_workbook(filename='reviews-sample.xlsx', read_only=True)\n",
    "ws = wb.active\n",
    "\n",
    "products = []\n",
    "reviews = []\n",
    "\n",
    "for row in ws.iter_rows(min_row=2, values_only=True):\n",
    "    product = Product(id=row[PRODUCT_ID], parent=row[PRODUCT_PARENT], title=row[PRODUCT_TITLE], category=row[PRODUCT_CATEGORY] )\n",
    "    products.append(product)\n",
    "\n",
    "    spread_date = row[REVIEW_DATE]\n",
    "    parsed_date = datetime.strptime(spread_date, '%Y-%m-%d')\n",
    "    \n",
    "    review = Review(id=row[REVIEW_ID], customer_id=row[REVIEW_CUSTOMER],\n",
    "                    stars=row[REVIEW_STARS],\n",
    "                    headline=row[REVIEW_HEADLINE],\n",
    "                    body=row[REVIEW_BODY],\n",
    "                    date=parsed_date)\n",
    "    reviews.append(review)\n",
    "\n",
    "print(products[0])\n",
    "print(reviews[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.ExcelFile # Loads Excel file from Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl1 = pd.ExcelFile('Beverage Sales FY21-23 Projection v5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl1.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in xl1.sheet_names:\n",
    "    wb.active = wb[sheet]\n",
    "    wb[sheet]['A1'] = 'Johnny'\n",
    "wb.save('Beverage Sales FY21-23 Projection v5 out.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxl1 = xl1.parse('Monthly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "op.load_workbook # loads Excel file with Openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=op.load_workbook('Beverage Sales FY21-23 Projection v5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in wb.sheetnames:\n",
    "    wb.active = wb[sheet]\n",
    "    wb[sheet]['A1'] = 'Johnny'\n",
    "wb.save('Beverage Sales FY21-23 Projection v5 out.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.active = wb['Monthly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_excel # Loads Excel selected worksheets as dataframes or dictionaries if several worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl2 = pd.read_excel('Beverage Sales FY21-23 Projection v5.xlsx', sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl2.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxl2 = xl2['Sales Fcst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(xl2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in l:\n",
    "    xl2[sheet].iloc[1,1] = 'Johnny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl2['Sales Fcst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating across cells in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in ws.iter_rows(1,1,values_only=True):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for value in ws.iter_rows(2,None,4,7, values_only=True):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrievinga and entering values in cells in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['A1'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['A1'].value = 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entering a formula in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['P1'] = '=AVERAGE(H2:H100)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Member Dues Email (exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['A1'].valueimport openpyxl as op\n",
    "import smtplib as s\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = op.load_workbook('duesRecords.xlsx')\n",
    "sheet = wb['Sheet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastCol = sheet.max_column\n",
    "latestMonth = sheet.cell(row=1, column=lastCol).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaidMembers = {}\n",
    "for r in range(2, sheet.max_row + 1):\n",
    "    payment = sheet.cell(row=r, column=lastCol).value\n",
    "    if payment != 'paid':\n",
    "        name = sheet.cell(row=r, column=1).value\n",
    "        email = sheet.cell(row=r, column=2).value\n",
    "        unpaidMembers[name] = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaidMembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = s.SMTP('smtp.office365.com', 587)\n",
    "email.ehlo()\n",
    "email.starttls()\n",
    "email.login('joao.melo@brix.co.nz', 'TheL0dg3!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, email in unpaidMembers.items():\n",
    "    body = \"Subject: %s dues unpaid. \\nDear %s,\\nRecords show that you have not paid dues for %s. Please make this payment as soon as possible. Thank you!\" %(latestMonth, name, latestMonth)\n",
    "    print('Sending email to %s...' % email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\joao.melo\\PycharmProjects\\LearnPython')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=op.load_workbook('Cash Flow reports.xlsx')\n",
    "s = a.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "    s.row_dimensions[i+1].height=50\n",
    "a.save('Cash Flow Rerports Wide Rows.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in s.iter_rows(2,20,None,None):\n",
    "    s.row_dimensions.height=50\n",
    "a.save('Cash Flow Rerports Wide Rows.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.389px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "403.31px",
    "left": "1436.32px",
    "right": "20px",
    "top": "107.989px",
    "width": "427.287px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
